llama_zero = {
    "covid19": {
        "informativeness": {
            "Informative": {
                "precision": 0.984375,
                "recall": 0.7241379310344828,
                "f1-score": 0.8344370860927153,
                "support": 87.0
            },
            "Personal_Experience": {
                "precision": 1.0,
                "recall": 0.14285714285714285,
                "f1-score": 0.25,
                "support": 7.0
            },
            "none": {
                "precision": 0.53125,
                "recall": 0.9714285714285714,
                "f1-score": 0.6868686868686869,
                "support": 35.0
            },
            "accuracy": 0.7596899224806202,
            "macro avg": {
                "precision": 0.8385416666666666,
                "recall": 0.612807881773399,
                "f1-score": 0.5904352576538007,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.862281976744186,
                "recall": 0.7596899224806202,
                "f1-score": 0.7626855079881416,
                "support": 129.0
            }
        },
        "topic": {
            "Case_Report": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 37.0
            },
            "Consequences": {
                "precision": 0.25,
                "recall": 0.16666666666666666,
                "f1-score": 0.2,
                "support": 6.0
            },
            "Governm_Decisions": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 22.0
            },
            "Risk_Reduction": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "Vaccination": {
                "precision": 0.8,
                "recall": 0.21052631578947367,
                "f1-score": 0.3333333333333333,
                "support": 19.0
            },
            "none": {
                "precision": 0.35,
                "recall": 1.0,
                "f1-score": 0.5185185185185185,
                "support": 42.0
            },
            "accuracy": 0.3643410852713178,
            "macro avg": {
                "precision": 0.2333333333333333,
                "recall": 0.22953216374269006,
                "f1-score": 0.17530864197530863,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.2434108527131783,
                "recall": 0.3643410852713178,
                "f1-score": 0.22721791559000862,
                "support": 129.0
            }
        },
        "credibility": {
            "credible": {
                "precision": 0.75,
                "recall": 0.038461538461538464,
                "f1-score": 0.07317073170731707,
                "support": 78.0
            },
            "non-credible": {
                "precision": 0.021739130434782608,
                "recall": 0.3333333333333333,
                "f1-score": 0.04081632653061224,
                "support": 3.0
            },
            "none": {
                "precision": 0.22580645161290322,
                "recall": 0.14583333333333334,
                "f1-score": 0.17721518987341772,
                "support": 48.0
            },
            "micro avg": {
                "precision": 0.13580246913580246,
                "recall": 0.08527131782945736,
                "f1-score": 0.10476190476190476,
                "support": 129.0
            },
            "macro avg": {
                "precision": 0.3325151940158953,
                "recall": 0.17254273504273507,
                "f1-score": 0.09706741603711568,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.538014938517238,
                "recall": 0.08527131782945736,
                "f1-score": 0.1111325206719893,
                "support": 129.0
            }
        }
    },
    "speech_acts_coarse": {
        "coarse labels": {
            "ASSERTIVE": {
                "precision": 0.7857142857142857,
                "recall": 0.16058394160583941,
                "f1-score": 0.26666666666666666,
                "support": 137.0
            },
            "COMMISSIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4.0
            },
            "DIRECTIVE": {
                "precision": 0.3798449612403101,
                "recall": 0.3858267716535433,
                "f1-score": 0.3828125,
                "support": 127.0
            },
            "EXPRESSIVE": {
                "precision": 0.5,
                "recall": 0.0375,
                "f1-score": 0.06976744186046512,
                "support": 80.0
            },
            "OTHER": {
                "precision": 0.04854368932038835,
                "recall": 0.7142857142857143,
                "f1-score": 0.09090909090909091,
                "support": 14.0
            },
            "UNSURE": {
                "precision": 0.06666666666666667,
                "recall": 0.03333333333333333,
                "f1-score": 0.044444444444444446,
                "support": 30.0
            },
            "micro avg": {
                "precision": 0.22135416666666666,
                "recall": 0.21683673469387754,
                "f1-score": 0.2190721649484536,
                "support": 392.0
            },
            "macro avg": {
                "precision": 0.2967949338236085,
                "recall": 0.22192162681307173,
                "f1-score": 0.1424333573134445,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.5065377012011785,
                "recall": 0.21683673469387754,
                "f1-score": 0.23810708364344677,
                "support": 392.0
            }
        }
    },
    "speech_acts_fine": {
        "fine labels": {
            "ADDRESS": {
                "precision": 1.0,
                "recall": 0.48,
                "f1-score": 0.6486486486486487,
                "support": 75.0
            },
            "AGREE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "ASSERT": {
                "precision": 0.6190476190476191,
                "recall": 0.11016949152542373,
                "f1-score": 0.18705035971223022,
                "support": 118.0
            },
            "COMMISSIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4.0
            },
            "COMPLAIN": {
                "precision": 0.28440366972477066,
                "recall": 0.6078431372549019,
                "f1-score": 0.3875,
                "support": 51.0
            },
            "EXCLUDED": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "GUESS": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 5.0
            },
            "OTHER": {
                "precision": 0.21739130434782608,
                "recall": 0.3333333333333333,
                "f1-score": 0.2631578947368421,
                "support": 15.0
            },
            "PREDICT": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 7.0
            },
            "REJOICE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "REQUEST": {
                "precision": 0.16,
                "recall": 0.36363636363636365,
                "f1-score": 0.2222222222222222,
                "support": 33.0
            },
            "REQUIRE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 16.0
            },
            "SUGGEST": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "SUSTAIN": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "UNSURE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 30.0
            },
            "WISH": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 2.0
            },
            "expressEMOJI": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 21.0
            },
            "accuracy": 0.24744897959183673,
            "macro avg": {
                "precision": 0.1341672113600127,
                "recall": 0.11146954857353075,
                "f1-score": 0.10050465443058489,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.436461927981632,
                "recall": 0.24744897959183673,
                "f1-score": 0.2596015123700964,
                "support": 392.0
            }
        }
    },
    "hasoc2020": {
        "coarse labels": {
            "HOF": {
                "precision": 0.35918367346938773,
                "recall": 0.6567164179104478,
                "f1-score": 0.46437994722955145,
                "support": 134.0
            },
            "NOT": {
                "precision": 0.9620253164556962,
                "recall": 0.5816326530612245,
                "f1-score": 0.724960254372019,
                "support": 392.0
            },
            "micro avg": {
                "precision": 0.6556016597510373,
                "recall": 0.6007604562737643,
                "f1-score": 0.626984126984127,
                "support": 526.0
            },
            "macro avg": {
                "precision": 0.660604494962542,
                "recall": 0.6191745354858361,
                "f1-score": 0.5946701008007853,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.8084496887747736,
                "recall": 0.6007604562737643,
                "f1-score": 0.6585766780277402,
                "support": 526.0
            }
        },
        "fine labels": {
            "HATE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 24.0
            },
            "NONE": {
                "precision": 0.978021978021978,
                "recall": 0.4708994708994709,
                "f1-score": 0.6357142857142857,
                "support": 378.0
            },
            "OFFN": {
                "precision": 0.10181818181818182,
                "recall": 0.7777777777777778,
                "f1-score": 0.18006430868167203,
                "support": 36.0
            },
            "PRFN": {
                "precision": 0.4339622641509434,
                "recall": 0.26136363636363635,
                "f1-score": 0.3262411347517731,
                "support": 88.0
            },
            "micro avg": {
                "precision": 0.44901960784313727,
                "recall": 0.435361216730038,
                "f1-score": 0.4420849420849421,
                "support": 526.0
            },
            "macro avg": {
                "precision": 0.3784506059977758,
                "recall": 0.37751022126022127,
                "f1-score": 0.2855049322869327,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.7824076834278427,
                "recall": 0.435361216730038,
                "f1-score": 0.5237481653435289,
                "support": 526.0
            }
        }
    },
    "germeval2019_task12": {
        "coarse labels": {
            "OFFENSE": {
                "precision": 0.40878896269800713,
                "recall": 0.8247422680412371,
                "f1-score": 0.5466347796378545,
                "support": 970.0
            },
            "OTHER": {
                "precision": 0.9150743099787686,
                "recall": 0.41824357108199905,
                "f1-score": 0.5740925740925741,
                "support": 2061.0
            },
            "micro avg": {
                "precision": 0.5733011383235599,
                "recall": 0.5483338832068624,
                "f1-score": 0.560539629005059,
                "support": 3031.0
            },
            "macro avg": {
                "precision": 0.6619316363383878,
                "recall": 0.6214929195616181,
                "f1-score": 0.5603636768652143,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.7530496359892144,
                "recall": 0.5483338832068624,
                "f1-score": 0.5653053551479755,
                "support": 3031.0
            }
        },
        "fine labels": {
            "PROFANITY": {
                "precision": 0.06280193236714976,
                "recall": 0.11711711711711711,
                "f1-score": 0.08176100628930817,
                "support": 111.0
            },
            "INSULT": {
                "precision": 0.31045241809672386,
                "recall": 0.4335511982570806,
                "f1-score": 0.3618181818181818,
                "support": 459.0
            },
            "ABUSE": {
                "precision": 0.21,
                "recall": 0.2625,
                "f1-score": 0.23333333333333334,
                "support": 400.0
            },
            "OTHER": {
                "precision": 0.872668810289389,
                "recall": 0.658418243571082,
                "f1-score": 0.7505530973451328,
                "support": 2061.0
            },
            "micro avg": {
                "precision": 0.5766448501550121,
                "recall": 0.5522929726162983,
                "f1-score": 0.564206268958544,
                "support": 3031.0
            },
            "macro avg": {
                "precision": 0.36398079018831564,
                "recall": 0.3678966397363199,
                "f1-score": 0.356866404696489,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.6704187041918775,
                "recall": 0.5522929726162983,
                "f1-score": 0.5989354286091424,
                "support": 3031.0
            }
        }
    },
    "germeval2019_task3": {
        "offensive labels": {
            "EXPLICIT": {
                "precision": 0.9147286821705426,
                "recall": 0.14824120603015076,
                "f1-score": 0.25513513513513514,
                "support": 796.0
            },
            "IMPLICIT": {
                "precision": 0.1553030303030303,
                "recall": 0.917910447761194,
                "f1-score": 0.265658747300216,
                "support": 134.0
            },
            "micro avg": {
                "precision": 0.26167209554831705,
                "recall": 0.2591397849462366,
                "f1-score": 0.26039978390059426,
                "support": 930.0
            },
            "macro avg": {
                "precision": 0.5350158562367865,
                "recall": 0.5330758268956723,
                "f1-score": 0.26039694121767554,
                "support": 930.0
            },
            "weighted avg": {
                "precision": 0.8053060613638258,
                "recall": 0.2591397849462366,
                "f1-score": 0.2566514405438672,
                "support": 930.0
            }
        }
    },
    "germeval2021": {
        "toxic": {
            "0": {
                "precision": 0.7177121771217713,
                "recall": 0.6548821548821548,
                "f1-score": 0.6848591549295775,
                "support": 594.0
            },
            "1": {
                "precision": 0.4910025706940874,
                "recall": 0.5457142857142857,
                "f1-score": 0.516914749661705,
                "support": 350.0
            },
            "micro avg": {
                "precision": 0.6229860365198711,
                "recall": 0.614406779661017,
                "f1-score": 0.6186666666666667,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.6043573739079293,
                "recall": 0.6002982202982203,
                "f1-score": 0.6008869522956413,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6336567086369309,
                "recall": 0.614406779661017,
                "f1-score": 0.6225916317900061,
                "support": 944.0
            }
        },
        "engaging": {
            "0": {
                "precision": 0.7735849056603774,
                "recall": 0.5933429811866859,
                "f1-score": 0.6715806715806716,
                "support": 691.0
            },
            "1": {
                "precision": 0.3213367609254499,
                "recall": 0.49407114624505927,
                "f1-score": 0.3894080996884735,
                "support": 253.0
            },
            "micro avg": {
                "precision": 0.5821545157780196,
                "recall": 0.5667372881355932,
                "f1-score": 0.5743424584004294,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.5474608332929136,
                "recall": 0.5437070637158726,
                "f1-score": 0.5304943856345725,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6523785702600208,
                "recall": 0.5667372881355932,
                "f1-score": 0.5959560310205804,
                "support": 944.0
            }
        },
        "factClaiming": {
            "0": {
                "precision": 0.8475836431226765,
                "recall": 0.3619047619047619,
                "f1-score": 0.5072302558398221,
                "support": 630.0
            },
            "1": {
                "precision": 0.40358744394618834,
                "recall": 0.8598726114649682,
                "f1-score": 0.5493387589013224,
                "support": 314.0
            },
            "micro avg": {
                "precision": 0.5309168443496801,
                "recall": 0.527542372881356,
                "f1-score": 0.5292242295430393,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.6255855435344324,
                "recall": 0.6108886866848651,
                "f1-score": 0.5282845073705722,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6998984667016838,
                "recall": 0.527542372881356,
                "f1-score": 0.5212366858835839,
                "support": 944.0
            }
        }
    }
}

eurollm_zero = {
    "covid19": {
        "informativeness": {
            "Informative": {
                "precision": 0.7238095238095238,
                "recall": 0.8735632183908046,
                "f1-score": 0.7916666666666666,
                "support": 87.0
            },
            "Personal_Experience": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 7.0
            },
            "none": {
                "precision": 0.8333333333333334,
                "recall": 0.14285714285714285,
                "f1-score": 0.24390243902439024,
                "support": 35.0
            },
            "micro avg": {
                "precision": 0.7297297297297297,
                "recall": 0.627906976744186,
                "f1-score": 0.675,
                "support": 129.0
            },
            "macro avg": {
                "precision": 0.5190476190476191,
                "recall": 0.33880678708264916,
                "f1-score": 0.345189701897019,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.7142488002953119,
                "recall": 0.627906976744186,
                "f1-score": 0.6000898090376252,
                "support": 129.0
            }
        },
        "topic": {
            "Case_Report": {
                "precision": 0.4,
                "recall": 0.10810810810810811,
                "f1-score": 0.1702127659574468,
                "support": 37.0
            },
            "Consequences": {
                "precision": 0.05263157894736842,
                "recall": 0.16666666666666666,
                "f1-score": 0.08,
                "support": 6.0
            },
            "Governm_Decisions": {
                "precision": 0.5,
                "recall": 0.22727272727272727,
                "f1-score": 0.3125,
                "support": 22.0
            },
            "Risk_Reduction": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "Vaccination": {
                "precision": 0.42857142857142855,
                "recall": 0.15789473684210525,
                "f1-score": 0.23076923076923078,
                "support": 19.0
            },
            "none": {
                "precision": 0.45454545454545453,
                "recall": 0.35714285714285715,
                "f1-score": 0.4,
                "support": 42.0
            },
            "micro avg": {
                "precision": 0.3111111111111111,
                "recall": 0.21705426356589147,
                "f1-score": 0.2557077625570776,
                "support": 129.0
            },
            "macro avg": {
                "precision": 0.3059580770107086,
                "recall": 0.1695141826720774,
                "f1-score": 0.19891366612111291,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.41356244734457714,
                "recall": 0.21705426356589147,
                "f1-score": 0.2700580443801621,
                "support": 129.0
            }
        },
        "credibility": {
            "credible": {
                "precision": 1.0,
                "recall": 0.0641025641025641,
                "f1-score": 0.12048192771084337,
                "support": 78.0
            },
            "non-credible": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "none": {
                "precision": 0.4,
                "recall": 0.041666666666666664,
                "f1-score": 0.07547169811320754,
                "support": 48.0
            },
            "micro avg": {
                "precision": 0.5384615384615384,
                "recall": 0.05426356589147287,
                "f1-score": 0.09859154929577464,
                "support": 129.0
            },
            "macro avg": {
                "precision": 0.4666666666666666,
                "recall": 0.03525641025641025,
                "f1-score": 0.06531787527468363,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.7534883720930233,
                "recall": 0.05426356589147287,
                "f1-score": 0.10093203000681972,
                "support": 129.0
            }
        }
    },
    "speech_acts_coarse": {
        "coarse labels": {
            "ASSERTIVE": {
                "precision": 0.24242424242424243,
                "recall": 0.058394160583941604,
                "f1-score": 0.09411764705882353,
                "support": 137.0
            },
            "COMMISSIVE": {
                "precision": 0.01639344262295082,
                "recall": 0.25,
                "f1-score": 0.03076923076923077,
                "support": 4.0
            },
            "DIRECTIVE": {
                "precision": 0.4125,
                "recall": 0.25984251968503935,
                "f1-score": 0.3188405797101449,
                "support": 127.0
            },
            "EXPRESSIVE": {
                "precision": 0.26851851851851855,
                "recall": 0.3625,
                "f1-score": 0.30851063829787234,
                "support": 80.0
            },
            "OTHER": {
                "precision": 0.1,
                "recall": 0.2857142857142857,
                "f1-score": 0.14814814814814814,
                "support": 14.0
            },
            "UNSURE": {
                "precision": 0.11764705882352941,
                "recall": 0.13333333333333333,
                "f1-score": 0.125,
                "support": 30.0
            },
            "micro avg": {
                "precision": 0.22191011235955055,
                "recall": 0.20153061224489796,
                "f1-score": 0.21122994652406418,
                "support": 392.0
            },
            "macro avg": {
                "precision": 0.19291387706487353,
                "recall": 0.2249640498861,
                "f1-score": 0.17089770733070328,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.28590838833877646,
                "recall": 0.20153061224489796,
                "f1-score": 0.21432365645721432,
                "support": 392.0
            }
        }
    },
    "speech_acts_fine": {
        "fine labels": {
            "ADDRESS": {
                "precision": 0.7258064516129032,
                "recall": 0.6,
                "f1-score": 0.656934306569343,
                "support": 75.0
            },
            "AGREE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "ASSERT": {
                "precision": 0.6111111111111112,
                "recall": 0.09322033898305085,
                "f1-score": 0.16176470588235295,
                "support": 118.0
            },
            "COMMISSIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4.0
            },
            "COMPLAIN": {
                "precision": 0.25165562913907286,
                "recall": 0.7450980392156863,
                "f1-score": 0.37623762376237624,
                "support": 51.0
            },
            "EXCLUDED": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "GUESS": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 5.0
            },
            "OTHER": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 15.0
            },
            "PREDICT": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 7.0
            },
            "REJOICE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "REQUEST": {
                "precision": 0.42857142857142855,
                "recall": 0.09090909090909091,
                "f1-score": 0.15,
                "support": 33.0
            },
            "REQUIRE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 16.0
            },
            "SUGGEST": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "SUSTAIN": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "UNSURE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 30.0
            },
            "WISH": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 2.0
            },
            "expressEMOJI": {
                "precision": 0.65,
                "recall": 0.6190476190476191,
                "f1-score": 0.6341463414634146,
                "support": 21.0
            },
            "micro avg": {
                "precision": 0.30726256983240224,
                "recall": 0.28061224489795916,
                "f1-score": 0.29333333333333333,
                "support": 392.0
            },
            "macro avg": {
                "precision": 0.15689086002555974,
                "recall": 0.12636912283267338,
                "f1-score": 0.11641664574573453,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.426464003089359,
                "recall": 0.28061224489795916,
                "f1-score": 0.26993239864650836,
                "support": 392.0
            }
        }
    },
    "hasoc2020": {
        "coarse labels": {
            "HOF": {
                "precision": 0.3655913978494624,
                "recall": 0.5074626865671642,
                "f1-score": 0.425,
                "support": 134.0
            },
            "NOT": {
                "precision": 0.8315789473684211,
                "recall": 0.20153061224489796,
                "f1-score": 0.324435318275154,
                "support": 392.0
            },
            "micro avg": {
                "precision": 0.5231316725978647,
                "recall": 0.279467680608365,
                "f1-score": 0.3643122676579926,
                "support": 526.0
            },
            "macro avg": {
                "precision": 0.5985851726089417,
                "recall": 0.3544966494060311,
                "f1-score": 0.374717659137577,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.7128672902666332,
                "recall": 0.279467680608365,
                "f1-score": 0.35005445772597027,
                "support": 526.0
            }
        },
        "fine labels": {
            "HATE": {
                "precision": 0.14285714285714285,
                "recall": 0.08333333333333333,
                "f1-score": 0.10526315789473684,
                "support": 24.0
            },
            "NONE": {
                "precision": 0.8817204301075269,
                "recall": 0.21693121693121692,
                "f1-score": 0.3481953290870488,
                "support": 378.0
            },
            "OFFN": {
                "precision": 0.08904109589041095,
                "recall": 0.7222222222222222,
                "f1-score": 0.15853658536585366,
                "support": 36.0
            },
            "PRFN": {
                "precision": 0.16666666666666666,
                "recall": 0.03409090909090909,
                "f1-score": 0.05660377358490566,
                "support": 88.0
            },
            "micro avg": {
                "precision": 0.2709832134292566,
                "recall": 0.21482889733840305,
                "f1-score": 0.23966065747614,
                "support": 526.0
            },
            "macro avg": {
                "precision": 0.32007133388043685,
                "recall": 0.26414442039442043,
                "f1-score": 0.16714971148313623,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.6741274527147113,
                "recall": 0.21482889733840305,
                "f1-score": 0.27534714702095164,
                "support": 526.0
            }
        }
    },
    "germeval2019_task12": {
        "coarse labels": {
            "OFFENSE": {
                "precision": 0.4256,
                "recall": 0.822680412371134,
                "f1-score": 0.5609841827768014,
                "support": 970.0
            },
            "OTHER": {
                "precision": 0.8745800671892497,
                "recall": 0.3789422610383309,
                "f1-score": 0.5287745429925524,
                "support": 2061.0
            },
            "micro avg": {
                "precision": 0.5704479768786127,
                "recall": 0.5209501814582645,
                "f1-score": 0.5445766511467495,
                "support": 3031.0
            },
            "macro avg": {
                "precision": 0.6500900335946249,
                "recall": 0.6008113367047324,
                "f1-score": 0.5448793628846769,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.7308945953404962,
                "recall": 0.5209501814582645,
                "f1-score": 0.5390824778624704,
                "support": 3031.0
            }
        },
        "fine labels": {
            "PROFANITY": {
                "precision": 0.05673758865248227,
                "recall": 0.2882882882882883,
                "f1-score": 0.09481481481481481,
                "support": 111.0
            },
            "INSULT": {
                "precision": 0.2031586503948313,
                "recall": 0.616557734204793,
                "f1-score": 0.30561555075593955,
                "support": 459.0
            },
            "ABUSE": {
                "precision": 0.20809248554913296,
                "recall": 0.09,
                "f1-score": 0.1256544502617801,
                "support": 400.0
            },
            "OTHER": {
                "precision": 0.8765182186234818,
                "recall": 0.21009218825812712,
                "f1-score": 0.33894324853228963,
                "support": 2061.0
            },
            "micro avg": {
                "precision": 0.29878048780487804,
                "recall": 0.2586605080831409,
                "f1-score": 0.2772767462422635,
                "support": 3031.0
            },
            "macro avg": {
                "precision": 0.3361267358049821,
                "recall": 0.3012345526878021,
                "f1-score": 0.216257016091206,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.6563143304765101,
                "recall": 0.2586605080831409,
                "f1-score": 0.2968082473016106,
                "support": 3031.0
            }
        }
    },
    "germeval2019_task3": {
        "offensive labels": {
            "EXPLICIT": {
                "precision": 0.8606060606060606,
                "recall": 0.17839195979899497,
                "f1-score": 0.29552549427679503,
                "support": 796.0
            },
            "IMPLICIT": {
                "precision": 0.14185639229422067,
                "recall": 0.6044776119402985,
                "f1-score": 0.2297872340425532,
                "support": 134.0
            },
            "micro avg": {
                "precision": 0.3029891304347826,
                "recall": 0.23978494623655913,
                "f1-score": 0.26770708283313327,
                "support": 930.0
            },
            "macro avg": {
                "precision": 0.5012312264501406,
                "recall": 0.39143478586964675,
                "f1-score": 0.2626563641596741,
                "support": 930.0
            },
            "weighted avg": {
                "precision": 0.7570442804406987,
                "recall": 0.23978494623655913,
                "f1-score": 0.286053529898958,
                "support": 930.0
            }
        }
    },
    "germeval2021": {
        "toxic": {
            "0": {
                "precision": 0.7384615384615385,
                "recall": 0.16161616161616163,
                "f1-score": 0.26519337016574585,
                "support": 594.0
            },
            "1": {
                "precision": 0.39325842696629215,
                "recall": 0.8,
                "f1-score": 0.527306967984934,
                "support": 350.0
            },
            "micro avg": {
                "precision": 0.44655581947743467,
                "recall": 0.3983050847457627,
                "f1-score": 0.42105263157894735,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.5658599827139154,
                "recall": 0.48080808080808085,
                "f1-score": 0.39625016907533994,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6104730966995299,
                "recall": 0.3983050847457627,
                "f1-score": 0.3623753185097245,
                "support": 944.0
            }
        },
        "engaging": {
            "0": {
                "precision": 0.7912772585669782,
                "recall": 0.3675832127351664,
                "f1-score": 0.5019762845849802,
                "support": 691.0
            },
            "1": {
                "precision": 0.325,
                "recall": 0.616600790513834,
                "f1-score": 0.4256480218281037,
                "support": 253.0
            },
            "micro avg": {
                "precision": 0.5118601747815231,
                "recall": 0.4343220338983051,
                "f1-score": 0.4699140401146132,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.5581386292834891,
                "recall": 0.4920920016245002,
                "f1-score": 0.46381215320654195,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6663110017688368,
                "recall": 0.4343220338983051,
                "f1-score": 0.48151966331645285,
                "support": 944.0
            }
        },
        "factClaiming": {
            "0": {
                "precision": 0.797752808988764,
                "recall": 0.1126984126984127,
                "f1-score": 0.19749652294853964,
                "support": 630.0
            },
            "1": {
                "precision": 0.3450064850843061,
                "recall": 0.8471337579617835,
                "f1-score": 0.49032258064516127,
                "support": 314.0
            },
            "micro avg": {
                "precision": 0.3918604651162791,
                "recall": 0.3569915254237288,
                "f1-score": 0.3736141906873614,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.5713796470365351,
                "recall": 0.4799160853300981,
                "f1-score": 0.34390955179685045,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6471571037917303,
                "recall": 0.3569915254237288,
                "f1-score": 0.2948984107840684,
                "support": 944.0
            }
        }
    }
}

teuken_zero = {
    "covid19": {
        "informativeness": {
            "Informative": {
                "precision": 0.7909090909090909,
                "recall": 1.0,
                "f1-score": 0.883248730964467,
                "support": 87.0
            },
            "Personal_Experience": {
                "precision": 0.23076923076923078,
                "recall": 0.42857142857142855,
                "f1-score": 0.3,
                "support": 7.0
            },
            "none": {
                "precision": 1.0,
                "recall": 0.17142857142857143,
                "f1-score": 0.2926829268292683,
                "support": 35.0
            },
            "accuracy": 0.7441860465116279,
            "macro avg": {
                "precision": 0.6738927738927739,
                "recall": 0.5333333333333333,
                "f1-score": 0.49197721926457844,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.8172439963137638,
                "recall": 0.7441860465116279,
                "f1-score": 0.6913685428909536,
                "support": 129.0
            }
        },
        "topic": {
            "Case_Report": {
                "precision": 0.875,
                "recall": 0.1891891891891892,
                "f1-score": 0.3111111111111111,
                "support": 37.0
            },
            "Consequences": {
                "precision": 0.1388888888888889,
                "recall": 0.8333333333333334,
                "f1-score": 0.23809523809523808,
                "support": 6.0
            },
            "Governm_Decisions": {
                "precision": 0.8,
                "recall": 0.18181818181818182,
                "f1-score": 0.2962962962962963,
                "support": 22.0
            },
            "Risk_Reduction": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "Vaccination": {
                "precision": 0.45161290322580644,
                "recall": 0.7368421052631579,
                "f1-score": 0.56,
                "support": 19.0
            },
            "none": {
                "precision": 0.5,
                "recall": 0.2857142857142857,
                "f1-score": 0.36363636363636365,
                "support": 42.0
            },
            "micro avg": {
                "precision": 0.35,
                "recall": 0.32558139534883723,
                "f1-score": 0.3373493975903614,
                "support": 129.0
            },
            "macro avg": {
                "precision": 0.4609169653524492,
                "recall": 0.371149515886358,
                "f1-score": 0.29485650152316817,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.6231703759273152,
                "recall": 0.32558139534883723,
                "f1-score": 0.3517126227203747,
                "support": 129.0
            }
        },
        "credibility": {
            "credible": {
                "precision": 0.7959183673469388,
                "recall": 0.5,
                "f1-score": 0.6141732283464567,
                "support": 78.0
            },
            "non-credible": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "none": {
                "precision": 0.4383561643835616,
                "recall": 0.6666666666666666,
                "f1-score": 0.5289256198347108,
                "support": 48.0
            },
            "accuracy": 0.5503875968992248,
            "macro avg": {
                "precision": 0.4114248439101668,
                "recall": 0.38888888888888884,
                "f1-score": 0.3810329493937225,
                "support": 129.0
            },
            "weighted avg": {
                "precision": 0.6443622367711023,
                "recall": 0.5503875968992248,
                "f1-score": 0.5681700896363545,
                "support": 129.0
            }
        }
    },
    "speech_acts_coarse": {
        "coarse labels": {
            "ASSERTIVE": {
                "precision": 0.37777777777777777,
                "recall": 0.9927007299270073,
                "f1-score": 0.5472837022132797,
                "support": 137.0
            },
            "COMMISSIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4.0
            },
            "DIRECTIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 127.0
            },
            "EXPRESSIVE": {
                "precision": 1.0,
                "recall": 0.0125,
                "f1-score": 0.024691358024691357,
                "support": 80.0
            },
            "OTHER": {
                "precision": 0.07692307692307693,
                "recall": 0.07142857142857142,
                "f1-score": 0.07407407407407407,
                "support": 14.0
            },
            "UNSURE": {
                "precision": 0.06666666666666667,
                "recall": 0.03333333333333333,
                "f1-score": 0.044444444444444446,
                "support": 30.0
            },
            "micro avg": {
                "precision": 0.35732647814910024,
                "recall": 0.35459183673469385,
                "f1-score": 0.3559539052496799,
                "support": 392.0
            },
            "macro avg": {
                "precision": 0.25356125356125353,
                "recall": 0.18499377244815204,
                "f1-score": 0.1150822631260816,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.34396040467469036,
                "recall": 0.35459183673469385,
                "f1-score": 0.20235598524378823,
                "support": 392.0
            }
        }
    },
    "speech_acts_fine": {
        "fine labels": {
            "ADDRESS": {
                "precision": 0.35294117647058826,
                "recall": 0.16,
                "f1-score": 0.22018348623853212,
                "support": 75.0
            },
            "AGREE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "ASSERT": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 118.0
            },
            "COMMISSIVE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4.0
            },
            "COMPLAIN": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 51.0
            },
            "EXCLUDED": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "GUESS": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 5.0
            },
            "OTHER": {
                "precision": 0.05627705627705628,
                "recall": 0.8666666666666667,
                "f1-score": 0.10569105691056911,
                "support": 15.0
            },
            "PREDICT": {
                "precision": 0.06666666666666667,
                "recall": 0.7142857142857143,
                "f1-score": 0.12195121951219512,
                "support": 7.0
            },
            "REJOICE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "REQUEST": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 33.0
            },
            "REQUIRE": {
                "precision": 0.1,
                "recall": 0.0625,
                "f1-score": 0.07692307692307693,
                "support": 16.0
            },
            "SUGGEST": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "SUSTAIN": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 3.0
            },
            "UNSURE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 30.0
            },
            "WISH": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 2.0
            },
            "expressEMOJI": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 21.0
            },
            "micro avg": {
                "precision": 0.08266666666666667,
                "recall": 0.07908163265306123,
                "f1-score": 0.08083441981747067,
                "support": 392.0
            },
            "macro avg": {
                "precision": 0.033875582318488896,
                "recall": 0.10608543417366947,
                "f1-score": 0.03086757879908078,
                "support": 392.0
            },
            "weighted avg": {
                "precision": 0.07495257843397099,
                "recall": 0.07908163265306123,
                "f1-score": 0.0514886609410792,
                "support": 392.0
            }
        }
    },
    "hasoc2020": {
        "coarse labels": {
            "HOF": {
                "precision": 0.25769230769230766,
                "recall": 1.0,
                "f1-score": 0.40978593272171254,
                "support": 134.0
            },
            "NOT": {
                "precision": 1.0,
                "recall": 0.015306122448979591,
                "f1-score": 0.03015075376884422,
                "support": 392.0
            },
            "accuracy": 0.2661596958174905,
            "macro avg": {
                "precision": 0.6288461538461538,
                "recall": 0.5076530612244898,
                "f1-score": 0.2199683432452784,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.8108949985375841,
                "recall": 0.2661596958174905,
                "f1-score": 0.12686389821691332,
                "support": 526.0
            }
        },
        "fine labels": {
            "HATE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 24.0
            },
            "NONE": {
                "precision": 0.9655172413793104,
                "recall": 0.07407407407407407,
                "f1-score": 0.1375921375921376,
                "support": 378.0
            },
            "OFFN": {
                "precision": 0.07272727272727272,
                "recall": 1.0,
                "f1-score": 0.13559322033898305,
                "support": 36.0
            },
            "PRFN": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 88.0
            },
            "micro avg": {
                "precision": 0.1219047619047619,
                "recall": 0.12167300380228137,
                "f1-score": 0.12178877259752617,
                "support": 526.0
            },
            "macro avg": {
                "precision": 0.25956112852664576,
                "recall": 0.2685185185185185,
                "f1-score": 0.06829633948278016,
                "support": 526.0
            },
            "weighted avg": {
                "precision": 0.6988283252082911,
                "recall": 0.12167300380228137,
                "f1-score": 0.10815814437648556,
                "support": 526.0
            }
        }
    },
    "germeval2019_task12": {
        "coarse labels": {
            "OFFENSE": {
                "precision": 0.32002639392939625,
                "recall": 1.0,
                "f1-score": 0.48487878030492376,
                "support": 970.0
            },
            "OTHER": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 2061.0
            },
            "accuracy": 0.32002639392939625,
            "macro avg": {
                "precision": 0.16001319696469812,
                "recall": 0.5,
                "f1-score": 0.24243939015246188,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.10241689281145311,
                "recall": 0.32002639392939625,
                "f1-score": 0.1551740075538687,
                "support": 3031.0
            }
        },
        "fine labels": {
            "PROFANITY": {
                "precision": 0.05128205128205128,
                "recall": 0.018018018018018018,
                "f1-score": 0.02666666666666667,
                "support": 111.0
            },
            "INSULT": {
                "precision": 0.18788958147818344,
                "recall": 0.9193899782135077,
                "f1-score": 0.3120147874306839,
                "support": 459.0
            },
            "ABUSE": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 400.0
            },
            "OTHER": {
                "precision": 0.9293478260869565,
                "recall": 0.3318777292576419,
                "f1-score": 0.489095459420808,
                "support": 2061.0
            },
            "micro avg": {
                "precision": 0.3661599471249174,
                "recall": 0.3655559221379083,
                "f1-score": 0.365857685322767,
                "support": 3031.0
            },
            "macro avg": {
                "precision": 0.2921298647117978,
                "recall": 0.3173214313722919,
                "f1-score": 0.20694422837953963,
                "support": 3031.0
            },
            "weighted avg": {
                "precision": 0.6622631128855201,
                "recall": 0.3655559221379083,
                "f1-score": 0.3807985909920717,
                "support": 3031.0
            }
        }
    },
    "germeval2019_task3": {
        "offensive labels": {
            "EXPLICIT": {
                "precision": 0.8559139784946237,
                "recall": 1.0,
                "f1-score": 0.9223638470451911,
                "support": 796.0
            },
            "IMPLICIT": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 134.0
            },
            "accuracy": 0.8559139784946237,
            "macro avg": {
                "precision": 0.42795698924731185,
                "recall": 0.5,
                "f1-score": 0.46118192352259557,
                "support": 930.0
            },
            "weighted avg": {
                "precision": 0.7325887385824952,
                "recall": 0.8559139784946237,
                "f1-score": 0.7894641099440561,
                "support": 930.0
            }
        }
    },
    "germeval2021": {
        "toxic": {
            "0": {
                "precision": 0.8405797101449275,
                "recall": 0.09764309764309764,
                "f1-score": 0.17496229260935142,
                "support": 594.0
            },
            "1": {
                "precision": 0.38940092165898615,
                "recall": 0.9657142857142857,
                "f1-score": 0.555008210180624,
                "support": 350.0
            },
            "micro avg": {
                "precision": 0.4226254002134472,
                "recall": 0.4194915254237288,
                "f1-score": 0.42105263157894735,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.6149903159019569,
                "recall": 0.5316786916786918,
                "f1-score": 0.3649852513949877,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.6732994389901823,
                "recall": 0.4194915254237288,
                "f1-score": 0.3158691476410732,
                "support": 944.0
            }
        },
        "engaging": {
            "0": {
                "precision": 0.8317757009345794,
                "recall": 0.1287988422575977,
                "f1-score": 0.22305764411027568,
                "support": 691.0
            },
            "1": {
                "precision": 0.2818955042527339,
                "recall": 0.9169960474308301,
                "f1-score": 0.4312267657992565,
                "support": 253.0
            },
            "micro avg": {
                "precision": 0.34516129032258064,
                "recall": 0.3400423728813559,
                "f1-score": 0.3425827107790822,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.5568356025936567,
                "recall": 0.5228974448442139,
                "f1-score": 0.3271422049547661,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.684403148222178,
                "recall": 0.3400423728813559,
                "f1-score": 0.27884873286802164,
                "support": 944.0
            }
        },
        "factClaiming": {
            "0": {
                "precision": 1.0,
                "recall": 0.006349206349206349,
                "f1-score": 0.012618296529968454,
                "support": 630.0
            },
            "1": {
                "precision": 0.3333333333333333,
                "recall": 0.9968152866242038,
                "f1-score": 0.49960095770151636,
                "support": 314.0
            },
            "micro avg": {
                "precision": 0.3361611876988335,
                "recall": 0.3358050847457627,
                "f1-score": 0.3359830418653948,
                "support": 944.0
            },
            "macro avg": {
                "precision": 0.6666666666666666,
                "recall": 0.5015822464867051,
                "f1-score": 0.2561096271157424,
                "support": 944.0
            },
            "weighted avg": {
                "precision": 0.7782485875706214,
                "recall": 0.3358050847457627,
                "f1-score": 0.17460193594508078,
                "support": 944.0
            }
        }
    }
}